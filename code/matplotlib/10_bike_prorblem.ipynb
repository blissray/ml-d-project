{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Prediction: Kaggle Bike Sharing Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@satishkt @sialan\n",
    "\n",
    "Lorem ipsum delorum..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n",
      "(100, 9) (100, 3)\n",
      "Index([u'datetime', u'season', u'holiday', u'workingday', u'weather', u'temp', u'atemp', u'humidity', u'windspeed'], dtype='object')\n",
      "datetime       object\n",
      "season          int64\n",
      "holiday         int64\n",
      "workingday      int64\n",
      "weather         int64\n",
      "temp          float64\n",
      "atemp         float64\n",
      "humidity        int64\n",
      "windspeed     float64\n",
      "dtype: object\n",
      "Index([u'casual', u'registered', u'count'], dtype='object')\n",
      "casual        int64\n",
      "registered    int64\n",
      "count         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "bike_sharing_demand = pd.read_csv('./data/input/train.csv')\n",
    "prediction_data = pd.read_csv('./data/input/test.csv')\n",
    "print bike_sharing_demand.shape\n",
    "\n",
    "train_data, train_labels = bike_sharing_demand.ix[:, 'datetime':'windspeed'], bike_sharing_demand.ix[:, 'casual':]\n",
    "prediction_data = prediction_data.ix[:, 'datetime':'windspeed']\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "mini_bike_sharing_demand = bike_sharing_demand.ix[shuffle[:100], :]\n",
    "mini_train_data, mini_train_labels = train_data.ix[shuffle[:100], :], train_labels.ix[shuffle[:100], :]\n",
    "print mini_train_data.shape, mini_train_labels.shape\n",
    "\n",
    "print train_data.columns\n",
    "print train_data.dtypes\n",
    "print train_labels.columns\n",
    "print train_labels.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a better handle on what we're working with..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Data Exploration\n",
    "# g = sns.pairplot(mini_bike_sharing_demand.ix[:, 'temp':'casual'], hue=\"casual\", palette=\"Set2\", diag_kind=\"kde\", size=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x1f2e2198>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFfCAYAAAAxo9Q/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAhIAAAAABCQAAAAABE9P87VokxfU53kAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f310978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexed_df = bike_sharing_demand.set_index('datetime').ix[:, 'count']\n",
    "indexed_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the value of the information in the timestamp, we need to extract it. We'll cover some more advanced feature engineering later on but this should help us out of the gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2011-01-01 00:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 81</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2011-01-01 01:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 9.02</td>\n",
       "      <td> 13.635</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2011-01-01 02:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 9.02</td>\n",
       "      <td> 13.635</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2011-01-01 03:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2011-01-01 04:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 5</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  hour  weekday  month  year  \n",
       "0        81          0     0        5      1  2011  \n",
       "1        80          0     1        5      1  2011  \n",
       "2        80          0     2        5      1  2011  \n",
       "3        75          0     3        5      1  2011  \n",
       "4        75          0     4        5      1  2011  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's extract the information\n",
    "for dataset in (train_data, prediction_data):\n",
    "    dataset['hour'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).hour)\n",
    "    dataset['weekday'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).weekday())\n",
    "    dataset['month'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).month)\n",
    "    dataset['year'] = dataset['datetime'].map(lambda x: (datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")).year)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move onto modelling, we can define a few functions to use going forward..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TRAIN:', array([ 4677,  4448,  5705, ...,  9845, 10799,  2732]), 'TEST:', array([6638, 7975, 5915, ..., 6860, 9596, 2663]))\n",
      "('TRAIN:', array([10386,  7496,  9182, ...,  1139,  2328,  2219]), 'TEST:', array([6395, 6832, 9781, ..., 2491, 6925, 6305]))\n",
      "('TRAIN:', array([ 1287,  6686,  3958, ...,  4151,   665, 10420]), 'TEST:', array([ 2075,  2707,  6480, ..., 10843,  7669,  2231]))\n",
      "('TRAIN:', array([5623, 5232, 5102, ..., 9615,  495, 1377]), 'TEST:', array([4024, 5941,   16, ..., 6469,  573, 3649]))\n",
      "('TRAIN:', array([ 121, 2774, 6844, ..., 9362, 6073, 8646]), 'TEST:', array([5481, 8121, 7550, ..., 5653, 6203, 3524]))\n",
      "('TRAIN:', array([3211, 3162, 1709, ...,  459, 1169, 3559]), 'TEST:', array([7341, 6238, 9430, ..., 9801, 5258, 5785]))\n",
      "('TRAIN:', array([ 2695,  8909,  7979, ...,  3635, 10203,  2596]), 'TEST:', array([7930, 1021, 4776, ..., 9878, 8776, 1113]))\n",
      "('TRAIN:', array([3614, 5140,  928, ...,  839, 1852, 1606]), 'TEST:', array([6553, 9310, 1568, ..., 6010,  439, 2633]))\n",
      "('TRAIN:', array([4720, 1323, 4715, ..., 2609, 9758, 9604]), 'TEST:', array([10826,  8944,  5650, ...,  4131,  4755,  2856]))\n",
      "('TRAIN:', array([5584, 6556,  450, ..., 5275,  210,  456]), 'TEST:', array([7766, 3685, 7400, ..., 9496, 2389, 7535]))\n"
     ]
    }
   ],
   "source": [
    "# Define the Root-Mean-Squared-Log Error function for scoring predictions\n",
    "def rmsle(actual_values, predicted_values):\n",
    "    squared_log_errors = (np.log(np.array(predicted_values) + 1) - np.log(np.array(actual_values) + 1)) ** 2\n",
    "    mean_squared_errors = np.nansum(squared_log_errors) / len(squared_log_errors)\n",
    "    return np.sqrt(mean_squared_errors)\n",
    "\n",
    "# Define cross-validation loop for training and testing\n",
    "rs = cross_validation.ShuffleSplit(train_data.shape[0], n_iter=10, random_state=0)\n",
    "for train_index, test_index in rs:\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model (Linear Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Error Loop 0: 1.17262495536\n",
      "Cross-Validated Error Loop 1: 1.18423803286\n",
      "Cross-Validated Error Loop 2: 1.17035666194\n",
      "Cross-Validated Error Loop 3: 1.15128236819\n",
      "Cross-Validated Error Loop 4: 1.1208367118\n",
      "Cross-Validated Error Loop 5: 1.13114804469\n",
      "Cross-Validated Error Loop 6: 1.14718152976\n",
      "Cross-Validated Error Loop 7: 1.15876066646\n",
      "Cross-Validated Error Loop 8: 1.12558267782\n",
      "Cross-Validated Error Loop 9: 1.15743021669\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    regr.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = regr.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Classical Statistical Forecasting Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional approaches to time-series forecasting assume an underlying stochastic process with some degree of stationarity. Using this assumption, auto-regressive (AR) approaches using VAR, ARIMA, or GARCH models are very common. However, unable to capture non-linear feature interaction...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try some traditional statistical forecasting models, ARIMA\n",
    "# arma = sm.tsa.ARIMA(src_data_model, order=(1,1,1), freq='W').fit(full_output=False, disp=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Machine Learning Approach To Time-Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern approaches to time-series forecasting leverage chaos theory and the assumption that the underlying process is not random, but ultimately deterministic and highly non-linear...ADD MORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A non-parametric approach based on ________ paper...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated Error Loop 0: 0.874831380405\n",
      "Cross-Validated Error Loop 1: 0.816448989085\n",
      "Cross-Validated Error Loop 2: 0.845769028824\n",
      "Cross-Validated Error Loop 3: 0.863034482382\n",
      "Cross-Validated Error Loop 4: 0.824645728344\n",
      "Cross-Validated Error Loop 5: 0.831427824698\n",
      "Cross-Validated Error Loop 6: 0.867591377324\n",
      "Cross-Validated Error Loop 7: 0.836196160394\n",
      "Cross-Validated Error Loop 8: 0.843380833742\n",
      "Cross-Validated Error Loop 9: 0.841398341874\n"
     ]
    }
   ],
   "source": [
    "# Create knn regression object\n",
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the model using the training sets\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    neigh.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = neigh.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A kernel method based on ____ paper...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create svr objects\n",
    "svr_lin = SVR(kernel='linear', C=1e3)\n",
    "svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "\n",
    "print(\"For the SVR using a linear kernel:\")\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    svr_lin.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = svr_lin.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))\n",
    "\"\"\"\n",
    "# Train the model using the training sets\n",
    "print(\"For the SVR using an rbf kernel:\")\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    svr_rbf.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = svr_rbf.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))\n",
    "    \n",
    "# Train the model using the training sets\n",
    "print(\"For the SVR using a polynomial kernel or degree 2:\")\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    svr_poly.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = svr_poly.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision-Tree Based Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF and GBM extend decision trees....really ensemble methods but we'll cover ensembling multiple models later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Random Forest model:\n",
      "Cross-Validated Error Loop 0: 0.357062993623\n",
      "Cross-Validated Error Loop 1: 0.319521364968\n",
      "Cross-Validated Error Loop 2: 0.320574357334\n",
      "Cross-Validated Error Loop 3: 0.340111790106\n",
      "Cross-Validated Error Loop 4: 0.32492139945\n",
      "Cross-Validated Error Loop 5: 0.324845814757\n",
      "Cross-Validated Error Loop 6: 0.325664160057\n",
      "Cross-Validated Error Loop 7: 0.340137989483\n",
      "Cross-Validated Error Loop 8: 0.328012599016\n",
      "Cross-Validated Error Loop 9: 0.32580457893\n",
      "\n",
      "For the Gradient Boosted Trees model:\n",
      "Cross-Validated Error Loop 0: 0.59509561285\n",
      "Cross-Validated Error Loop 1: 0.595152375499\n",
      "Cross-Validated Error Loop 2: 0.569883383723\n",
      "Cross-Validated Error Loop 3: 0.613558059052\n",
      "Cross-Validated Error Loop 4: 0.566935489885\n",
      "Cross-Validated Error Loop 5: 0.569727251467\n",
      "Cross-Validated Error Loop 6: 0.550634120313\n",
      "Cross-Validated Error Loop 7: 0.585498709599\n",
      "Cross-Validated Error Loop 8: 0.53910777445\n",
      "Cross-Validated Error Loop 9: 0.551717866881\n"
     ]
    }
   ],
   "source": [
    "# TODO: Random Forest and GBM Regression\n",
    "# Create rf and gbm regression object\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "gbm = GradientBoostingRegressor(loss='ls', alpha=0.95, n_estimators=500, max_depth=4, learning_rate=.01, min_samples_leaf=9, min_samples_split=9)\n",
    "\n",
    "# Train the model using the training sets\n",
    "print(\"For the Random Forest model:\")\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    rf.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = rf.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))\n",
    "    \n",
    "# Train the model using the training sets\n",
    "print(\"\\nFor the Gradient Boosted Trees model:\")\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    gbm.fit(train_data.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = gbm.predict(train_data.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start playing with the features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_dataframe(data, cols, replace=False):\n",
    "    \"\"\" Takes a dataframe and a list of columns that need to be encoded.\n",
    "    Returns a 3-tuple comprising the data, the vectorized data,\n",
    "    and the fitted vectorizer.\n",
    "    Modified from https://gist.github.com/kljensen/5452382\n",
    "    \"\"\"\n",
    "    enc = OneHotEncoder()\n",
    "    e = enc.fit_transform(data[cols].values)\n",
    "    vecData = pd.DataFrame(e.toarray())\n",
    "    if replace is True:\n",
    "        data = data.drop(cols, axis=1)\n",
    "        data = data.join(vecData)\n",
    "    return (data, vecData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_w3</th>\n",
       "      <th>humidity_w6</th>\n",
       "      <th>humidity_w12</th>\n",
       "      <th>humidity_w24</th>\n",
       "      <th>humidity_w48</th>\n",
       "      <th>windspeed_w3</th>\n",
       "      <th>windspeed_w6</th>\n",
       "      <th>windspeed_w12</th>\n",
       "      <th>windspeed_w24</th>\n",
       "      <th>windspeed_w48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2011-01-01 00:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 81</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td> 81.000000</td>\n",
       "      <td> 81.000000</td>\n",
       "      <td> 81</td>\n",
       "      <td> 81</td>\n",
       "      <td> 81</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2011-01-01 01:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.02</td>\n",
       "      <td> 13.635</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 1</td>\n",
       "      <td>...</td>\n",
       "      <td> 80.000000</td>\n",
       "      <td> 80.000000</td>\n",
       "      <td> 80</td>\n",
       "      <td> 80</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2011-01-01 02:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.02</td>\n",
       "      <td> 13.635</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 2</td>\n",
       "      <td>...</td>\n",
       "      <td> 80.333333</td>\n",
       "      <td> 80.000000</td>\n",
       "      <td> 80</td>\n",
       "      <td> 80</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2011-01-01 03:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 3</td>\n",
       "      <td>...</td>\n",
       "      <td> 78.333333</td>\n",
       "      <td> 75.000000</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2011-01-01 04:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 4</td>\n",
       "      <td>...</td>\n",
       "      <td> 76.666667</td>\n",
       "      <td> 75.000000</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 2011-01-01 05:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td>  9.84</td>\n",
       "      <td> 12.880</td>\n",
       "      <td> 75</td>\n",
       "      <td> 6.0032</td>\n",
       "      <td> 5</td>\n",
       "      <td>...</td>\n",
       "      <td> 75.000000</td>\n",
       "      <td> 77.666667</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 2.001067</td>\n",
       "      <td> 1.000533</td>\n",
       "      <td> 6.0032</td>\n",
       "      <td> 6.0032</td>\n",
       "      <td> 6.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 2011-01-01 06:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.02</td>\n",
       "      <td> 13.635</td>\n",
       "      <td> 80</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 6</td>\n",
       "      <td>...</td>\n",
       "      <td> 76.666667</td>\n",
       "      <td> 77.500000</td>\n",
       "      <td> 80</td>\n",
       "      <td> 80</td>\n",
       "      <td> 80</td>\n",
       "      <td> 2.001067</td>\n",
       "      <td> 1.000533</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 2011-01-01 07:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  8.20</td>\n",
       "      <td> 12.880</td>\n",
       "      <td> 86</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 7</td>\n",
       "      <td>...</td>\n",
       "      <td> 80.333333</td>\n",
       "      <td> 78.500000</td>\n",
       "      <td> 86</td>\n",
       "      <td> 86</td>\n",
       "      <td> 86</td>\n",
       "      <td> 2.001067</td>\n",
       "      <td> 1.000533</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 2011-01-01 08:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.84</td>\n",
       "      <td> 14.395</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 8</td>\n",
       "      <td>...</td>\n",
       "      <td> 80.333333</td>\n",
       "      <td> 77.666667</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 75</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000533</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 2011-01-01 09:00:00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 13.12</td>\n",
       "      <td> 17.425</td>\n",
       "      <td> 76</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 9</td>\n",
       "      <td>...</td>\n",
       "      <td> 79.000000</td>\n",
       "      <td> 77.833333</td>\n",
       "      <td> 76</td>\n",
       "      <td> 76</td>\n",
       "      <td> 76</td>\n",
       "      <td> 0.000000</td>\n",
       "      <td> 1.000533</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "      <td> 0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0  2011-01-01 00:00:00       1        0           0        1   9.84  14.395   \n",
       "1  2011-01-01 01:00:00       1        0           0        1   9.02  13.635   \n",
       "2  2011-01-01 02:00:00       1        0           0        1   9.02  13.635   \n",
       "3  2011-01-01 03:00:00       1        0           0        1   9.84  14.395   \n",
       "4  2011-01-01 04:00:00       1        0           0        1   9.84  14.395   \n",
       "5  2011-01-01 05:00:00       1        0           0        2   9.84  12.880   \n",
       "6  2011-01-01 06:00:00       1        0           0        1   9.02  13.635   \n",
       "7  2011-01-01 07:00:00       1        0           0        1   8.20  12.880   \n",
       "8  2011-01-01 08:00:00       1        0           0        1   9.84  14.395   \n",
       "9  2011-01-01 09:00:00       1        0           0        1  13.12  17.425   \n",
       "\n",
       "   humidity  windspeed  hour      ...        humidity_w3  humidity_w6  \\\n",
       "0        81     0.0000     0      ...          81.000000    81.000000   \n",
       "1        80     0.0000     1      ...          80.000000    80.000000   \n",
       "2        80     0.0000     2      ...          80.333333    80.000000   \n",
       "3        75     0.0000     3      ...          78.333333    75.000000   \n",
       "4        75     0.0000     4      ...          76.666667    75.000000   \n",
       "5        75     6.0032     5      ...          75.000000    77.666667   \n",
       "6        80     0.0000     6      ...          76.666667    77.500000   \n",
       "7        86     0.0000     7      ...          80.333333    78.500000   \n",
       "8        75     0.0000     8      ...          80.333333    77.666667   \n",
       "9        76     0.0000     9      ...          79.000000    77.833333   \n",
       "\n",
       "   humidity_w12  humidity_w24  humidity_w48  windspeed_w3  windspeed_w6  \\\n",
       "0            81            81            81      0.000000      0.000000   \n",
       "1            80            80            80      0.000000      0.000000   \n",
       "2            80            80            80      0.000000      0.000000   \n",
       "3            75            75            75      0.000000      0.000000   \n",
       "4            75            75            75      0.000000      0.000000   \n",
       "5            75            75            75      2.001067      1.000533   \n",
       "6            80            80            80      2.001067      1.000533   \n",
       "7            86            86            86      2.001067      1.000533   \n",
       "8            75            75            75      0.000000      1.000533   \n",
       "9            76            76            76      0.000000      1.000533   \n",
       "\n",
       "   windspeed_w12  windspeed_w24  windspeed_w48  \n",
       "0         0.0000         0.0000         0.0000  \n",
       "1         0.0000         0.0000         0.0000  \n",
       "2         0.0000         0.0000         0.0000  \n",
       "3         0.0000         0.0000         0.0000  \n",
       "4         0.0000         0.0000         0.0000  \n",
       "5         6.0032         6.0032         6.0032  \n",
       "6         0.0000         0.0000         0.0000  \n",
       "7         0.0000         0.0000         0.0000  \n",
       "8         0.0000         0.0000         0.0000  \n",
       "9         0.0000         0.0000         0.0000  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Add Sliding Windows\n",
    "# Add windowed features (simple moving average) for weather, temp, atemp, humidity, and windspeed\n",
    "train_data_windowed_features_three = pd.rolling_window(train_data.ix[:, 'temp':'windspeed'], 3, 'boxcar')\n",
    "train_data_windowed_features_six = pd.rolling_window(train_data.ix[:, 'temp':'windspeed'], 6, 'boxcar')\n",
    "train_data_windowed_features_twelve = pd.rolling_window(train_data.ix[:, 'temp':'windspeed'], 12, 'boxcar')\n",
    "train_data_windowed_features_twentyfour = pd.rolling_window(train_data.ix[:, 'temp':'windspeed'], 24, 'boxcar')\n",
    "train_data_windowed_features_fourtyeight = pd.rolling_window(train_data.ix[:, 'temp':'windspeed'], 48, 'boxcar')\n",
    "\n",
    "prediction_data_windowed_features_three = pd.rolling_window(prediction_data.ix[:, 'temp':'windspeed'], 3, 'boxcar')\n",
    "prediction_data_windowed_features_six = pd.rolling_window(prediction_data.ix[:, 'temp':'windspeed'], 6, 'boxcar')\n",
    "prediction_data_windowed_features_twelve = pd.rolling_window(prediction_data.ix[:, 'temp':'windspeed'], 12, 'boxcar')\n",
    "prediction_data_windowed_features_twentyfour = pd.rolling_window(prediction_data.ix[:, 'temp':'windspeed'], 24, 'boxcar')\n",
    "prediction_data_windowed_features_fourtyeight = pd.rolling_window(prediction_data.ix[:, 'temp':'windspeed'], 48, 'boxcar')\n",
    "\n",
    "train_data_combined = train_data.copy(deep=False)\n",
    "\n",
    "train_data_combined['temp_w3'] = train_data_windowed_features_three['temp']\n",
    "train_data_combined['temp_w6'] = train_data_windowed_features_six['temp']\n",
    "train_data_combined['temp_w12'] = train_data_windowed_features_twelve['temp']\n",
    "train_data_combined['temp_w24'] = train_data_windowed_features_twentyfour['temp']\n",
    "train_data_combined['temp_w48'] = train_data_windowed_features_fourtyeight['temp']\n",
    "train_data_combined = train_data_combined.apply(lambda x: x.fillna(value=train_data_combined['temp']))\n",
    "\n",
    "train_data_combined['atemp_w3'] = train_data_windowed_features_three['atemp']\n",
    "train_data_combined['atemp_w6'] = train_data_windowed_features_six['atemp']\n",
    "train_data_combined['atemp_w12'] = train_data_windowed_features_twelve['atemp']\n",
    "train_data_combined['atemp_w24'] = train_data_windowed_features_twentyfour['atemp']\n",
    "train_data_combined['atemp_w48'] = train_data_windowed_features_fourtyeight['atemp']\n",
    "train_data_combined = train_data_combined.apply(lambda x: x.fillna(value=train_data_combined['atemp']))\n",
    "\n",
    "train_data_combined['humidity_w3'] = train_data_windowed_features_three['humidity']\n",
    "train_data_combined['humidity_w6'] = train_data_windowed_features_six['humidity']\n",
    "train_data_combined['humidity_w12'] = train_data_windowed_features_twelve['humidity']\n",
    "train_data_combined['humidity_w24'] = train_data_windowed_features_twentyfour['humidity']\n",
    "train_data_combined['humidity_w48'] = train_data_windowed_features_fourtyeight['humidity']\n",
    "train_data_combined = train_data_combined.apply(lambda x: x.fillna(value=train_data_combined['humidity']))\n",
    "\n",
    "train_data_combined['windspeed_w3'] = train_data_windowed_features_three['windspeed']\n",
    "train_data_combined['windspeed_w6'] = train_data_windowed_features_six['windspeed']\n",
    "train_data_combined['windspeed_w12'] = train_data_windowed_features_twelve['windspeed']\n",
    "train_data_combined['windspeed_w24'] = train_data_windowed_features_twentyfour['windspeed']\n",
    "train_data_combined['windspeed_w48'] = train_data_windowed_features_fourtyeight['windspeed']\n",
    "train_data_combined = train_data_combined.apply(lambda x: x.fillna(value=train_data_combined['windspeed']))\n",
    "\n",
    "train_data_combined.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed, _ = one_hot_dataframe(train_data_combined, ['season', 'holiday', 'workingday', 'weather', 'hour', 'weekday', 'month', 'year'], replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add some techniques from signal processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built more features, we need to do some feature selection...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling: Round Two!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to try some of these models again with the advanced features...this time we'll optimize the parameters also...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Random Forest model:\n",
      "Cross-Validated Error Loop 0: 0.385209058287\n",
      "Cross-Validated Error Loop 1: 0.343968701309\n",
      "Cross-Validated Error Loop 2: 0.341783672202\n",
      "Cross-Validated Error Loop 3: 0.363716612971\n",
      "Cross-Validated Error Loop 4: 0.353490401761\n",
      "Cross-Validated Error Loop 5: 0.348524079696\n",
      "Cross-Validated Error Loop 6: 0.340564216447\n",
      "Cross-Validated Error Loop 7: 0.358355907028\n",
      "Cross-Validated Error Loop 8: 0.344382227124\n",
      "Cross-Validated Error Loop 9: 0.349259676984\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "\n",
    "# Train the model using the training sets\n",
    "print(\"For the Random Forest model:\")\n",
    "for i, (train_index, test_index) in enumerate(rs):\n",
    "    rf.fit(train_data_combined.ix[train_index, 'season':], train_labels.ix[train_index, 'count'])\n",
    "    prediction_values = rf.predict(train_data_combined.ix[test_index, 'season':])\n",
    "    print(\"Cross-Validated Error Loop {0}: {1}\".format(i, rmsle(train_labels.ix[test_index, 'count'], prediction_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our models all tuned, we can ensemble them together for superior performance...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For kaggle, we can simply build a csv using the sample submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now train using the RF model on the entire training set\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "param_grid = {'n_estimators': [100, 300, 500, 700, 1000], 'max_depth': [None, 1, 2, 3, 5], 'min_samples_split': [1, 2, 3, 5]}\n",
    "model = GridSearchCV(rf, param_grid=param_grid)\n",
    "model.fit(train_data.ix[:, 'season':], train_labels.ix[:, 'count'])\n",
    "\n",
    "# Make predictions\n",
    "prediction_values = model.predict(prediction_data.ix[:, 'season':])\n",
    "\n",
    "# Create submission from sample_submission file\n",
    "submission_df = pd.read_csv('./data/output/sampleSubmission.csv')\n",
    "submission_df['count'] = prediction_values\n",
    "submission_df.to_csv('./data/output/rf_tuned_windowedfeatures.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have we learned?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPENDIX: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using supervised learning, the sliding window approaches proved to be instrumental and feature engineering is obviously super important. However, with the modern advances in ML over the last few years, we can achieve the same (or superior) performance without domain-specific features. See LINK for tutorial, but ultimately the importance of Deep Learning is representation learning...ADD MORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RBM, Stacked Auto-encoders, DBN, CNN and RNN?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
